# See http://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
#
# To ban all spiders from the entire site uncomment the next two lines:
# User-agent: *
# Disallow: /
User-agent: *
Disallow: /catalog/facet # blocks facet pages
Crawl-delay: 10

User-agent: SemrushBot
Disallow: /
User-agent: claudebot
Disallow: /
User-agent: ClaudeBot
Disallow: /
User-agent: DataForSeoBot
Disallow: /
User-agent: Bytespider
Disallow: /

